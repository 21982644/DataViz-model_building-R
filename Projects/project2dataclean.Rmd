---
title: "CITS4009-Project 2"
output: prject2
---
#### Xiaoyu (21982644)

## Introduction
The dataset used for this project is pretty much the same as for the dataset used for project 1 (EDA) except this dataset has more observations. This dataset contains collected information on the mining injuries at U.S from 2000 to 2015 with 57 features and over 200,000 observations.

### Load Libraies
```{r}
library(dplyr)
library(vtreat)
library(ROCR)
library(ROCit)
library(rpart)
library(ggplot2)
library(knitr)
```

### Load the Data
```{r}
setwd("~/Downloads/CITS4009/Projects")
main <- read.csv("us_data.csv")
```

### Data Pre-processing
The data are cleaned as per project 1 with some modifications. Since we are already familiar with the data, this cleaning steps and explanation are not shown in full details. 

```{r}
# fill in the NA for days lost and days restricted
injury <- main %>%  mutate(DAYS_LOST = ifelse(DEGREE_INJURY == 'NO DYS AWY FRM WRK,NO RSTR ACT' | DEGREE_INJURY == 'DAYS RESTRICTED ACTIVITY ONLY', 0, DAYS_LOST)) %>% mutate(DAYS_RESTRICT = ifelse(DEGREE_INJURY == 'NO DYS AWY FRM WRK,NO RSTR ACT' | DEGREE_INJURY == 'DAYS AWAY FROM WORK ONLY', 0, DAYS_RESTRICT))
```

"DAYS_LOST","DAYS_RESTRICTED", "SCHEDULE_CHARGE" contain information about the degree of injury and, we'll get very good f1(0.988), recall(1), precision(0.977) score for decision tree. However, I don't thinks it's appropriate to include those variables in the model, it's more like telling the information rather than predict. 
```{r}
# select columns
keep <- c("SUBUNIT","ACCIDENT_DT","CAL_YR","CAL_QTR","ACCIDENT_TIME", "DEGREE_INJURY_CD", "FIPS_STATE_CD", "UG_LOCATION", "UG_MINING_METHOD", "MINING_EQUIP", "SHIFT_BEGIN_TIME", "CLASSIFICATION", "ACCIDENT_TYPE", "NO_INJURIES", "TOT_EXPER", "MINE_EXPER","JOB_EXPER", "OCCUPATION", "ACTIVITY","INJURY_SOURCE","NATURE_INJURY", "INJ_BODY_PART", "TRANS_TERM", "RETURN_TO_WORK_DT", "IMMED_NOTIFY","COAL_METAL_IND")

injury <- injury[which(names(injury) %in% keep)]
```

```{r}
# change invalid value to NA and fill the NA
injury <- mutate(injury, ACCIDENT_TIME = ifelse(ACCIDENT_TIME > 2400, NA, ACCIDENT_TIME)) %>% mutate(injury,SHIFT_BEGIN_TIME= ifelse(SHIFT_BEGIN_TIME > 2400, NA, SHIFT_BEGIN_TIME))

# change the time in a range of 1-24
injury <- injury %>% mutate(ACCIDENT_TIME_NEW=case_when(
  ACCIDENT_TIME < 100  ~  floor(injury$ACCIDENT_TIME/10),
  ACCIDENT_TIME >= 100 ~ floor(injury$ACCIDENT_TIME/100))) %>% 
  mutate(SHIFT_BEGIN_TIME_NEW=case_when(
  SHIFT_BEGIN_TIME < 100  ~  floor(injury$SHIFT_BEGIN_TIME /10),
  SHIFT_BEGIN_TIME >= 100 ~ floor(injury$SHIFT_BEGIN_TIME /100)))

# fill the NA as the median based the ACCIDENT_TIME and SHIFT_BEGIN_TIME, from EDA process we know that those two values are higher related 

injury <- injury %>%
    group_by(SHIFT_BEGIN_TIME_NEW) %>%
    mutate(Amedian = median(ACCIDENT_TIME_NEW, na.rm=TRUE))  %>% group_by(ACCIDENT_TIME_NEW) %>%
    mutate(Smedian = median(SHIFT_BEGIN_TIME_NEW, na.rm=TRUE))

injury <- injury %>% mutate(SHIFT_BEGIN_TIME_NEW = ifelse(is.na(SHIFT_BEGIN_TIME_NEW),Smedian, SHIFT_BEGIN_TIME_NEW)) %>% mutate(ACCIDENT_TIME_NEW = ifelse(is.na(ACCIDENT_TIME_NEW),Amedian,ACCIDENT_TIME_NEW))
```

```{r}
# add a column as days return to work 
injury <- within(injury, {
     ACCIDENT_DT      <- as.POSIXct(ACCIDENT_DT, format='%d/%m/%Y')
     RETURN_TO_WORK_DT<- as.POSIXct(RETURN_TO_WORK_DT, format='%m/%d/%Y')
})

injury$DAY_AWY <- difftime(injury$RETURN_TO_WORK_DT,injury$ACCIDENT_DT, units="days")

injury$DAY_AWY <- as.numeric(injury$DAY_AWY)
```

```{r}
# fill NA for experience variables 
injury <- mutate(injury, TOT_EXPER_NEW = ifelse(is.na(TOT_EXPER),
                                                       JOB_EXPER,
                                                       TOT_EXPER))

injury <- mutate(injury, TOT_EXPER_NEW = ifelse(is.na(TOT_EXPER),
                                                       MINE_EXPER,
                                                       TOT_EXPER))

injury <- mutate(injury, JOB_EXPER_NEW = ifelse(is.na(JOB_EXPER),
                                                       TOT_EXPER,
                                                       JOB_EXPER))

injury <- mutate(injury, MINE_EXPER_NEW = ifelse(is.na(MINE_EXPER),
                                                       TOT_EXPER,
                                                       MINE_EXPER))
```

```{r}
NAs <- apply(is.na(injury), 2, sum)
NAs[NAs>0]
```

```{r}
# still have some NAs, use vtreat to prepare the data

 varlist <- setdiff(colnames(injury),"DEGREE_INJURY_CD")

 treatment_plan <- design_missingness_treatment(injury, varlist = varlist)

 training_prepared <- prepare(treatment_plan,injury)
```

```{r}
# remove injury df to free memory
rm(injury)
```

## Part 1 - Classification

### Select the target variable
The response variable chosen for this project is the number of days lost that have affected by the accident.
I've focused on this target variable to help to classify whether the accidents will be cause days lost from work or not so the company can plan ahead and take countermeasures.The labels assigned to this variable are [0,1) for no days lost/no injuries or [1,Inf] for workers that have taken days away from work because the accident. The aim of this project is to use a number of feature variables to create a classification model to assess if an incident will involve extra attention or if countermeasures are needed due to number of days away from work.

Create a target variable based on the the degree injury number. 0 and 6 indicate there that employee had no injuries.
```{r}
training_prepared <-  training_prepared %>% 
                      subset(DEGREE_INJURY_CD %in% c("0", "1","2","3","4","5","6"))  %>%
                      mutate(DEGREE_INJURY_PRED = ifelse(DEGREE_INJURY_CD %in% c("0","6"), "no","yes"))

table(training_prepared$DEGREE_INJURY_PRED)
```

The split between day lost and no day lost is not 1:1 balanced but are very close, so addition methods like under-sampling or over-sampling is not needed.
```{r}
round(prop.table(table(training_prepared$DEGREE_INJURY_PRED)), 2)
```

### Select feature variables
Select input variables that are likely to be most useful to a model in order to predict the target variable, in this case, we want to select variables from the dataset that could help us to predict whether the incidents will cause day lost to the workers. The information gathered from EDA process and the data dictionary that was given are used to make an informed decision about the variable we could use. And this have almost done in the data cleaning step, which some variables were selected and kept in the previous step. 

```{r}
training_prepared <- training_prepared[,-which(names(training_prepared) %in% c("Amedian", "Smedian","ACCIDENT_DT","RETURN_TO_WORK_DT"))]
```

### Splitting
The code below is adapted from the lecture slide. 90% of the data will be used for training and the rest of them will be used for training. Out of the 90% of the training set, 10% of them will be used for calibration.
```{r}
set.seed(12345678)
rgroup <- runif(nrow(training_prepared)) < 0.9
dTrainAll <- training_prepared[rgroup,]
dTest <- training_prepared[!rgroup,]

outcomes <- c('DEGREE_INJURY_PRED','DEGREE_INJURY_CD')

vars <- setdiff(colnames(dTrainAll), outcomes)
catVars <- vars[sapply(dTrainAll[, vars], class) %in% c('factor', 'character')]
numericVars <- vars[sapply(dTrainAll[, vars], class) %in% c('numeric', 'integer')] 

useForCal <- rbinom(n=dim(dTrainAll)[1], size=1, prob=0.1) > 0 
dCal <- subset(dTrainAll, useForCal)
dTrain <- subset(dTrainAll, !useForCal)

rm(list=c('training_prepared','dTrainAll'))
```

Convert categrocial variable to factor
```{r message=FALSE, warning=FALSE}
for(d in catVars) {
     if(class(dTrain[, d]) == "character") dTrain[, d] <- as.factor(dTrain[, d])
     if(class(dCal[, d]) == "character") dCal[, d] <- as.factor(dCal[, d])
     if(class(dTest[, d]) == "character") dTest[, d] <- as.factor(dTest[, d])
}
```

### Single Variable Model(SVM)
#### Categorical
Function for SVM predictions for categorical variables.
```{r}
pos <- "yes"
mkPredC <- function(outCol, varCol, appCol) {
  pPos <- sum(outCol == pos) / length(outCol)
  naTab <- table(as.factor(outCol[is.na(varCol)]))
  pPosWna <- (naTab/sum(naTab))[pos]
  vTab <- table(as.factor(outCol), varCol)
  pPosWv <- (vTab[pos, ] + 1.0e-3*pPos) / (colSums(vTab) + 1.0e-3) 
  pred <- pPosWv[appCol]
  pred[is.na(appCol)] <- pPosWna
  pred[is.na(pred)] <- pPos
  pred
}
```

Data type has change to multi-type, need to change back to data.frame only.
```{r}
dTrain <- as.data.frame(dTrain)
dCal <- as.data.frame(dCal)
dTest <- as.data.frame(dTest)
```

```{r}
outcome <- "DEGREE_INJURY_PRED"
for(v in catVars) {
  pi <- paste('pred',v,sep='')
  dTrain[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dCal[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dCal[,v])
  dTest[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTest[,v])
}
```

Evaluate SVM for categorical variables.
```{r}
calcAUC <- function(predcol,outcol) {
  perf <- ROCR::performance(prediction(predcol,outcol==pos),'auc')
  as.numeric(perf@y.values) 
}
```

Processing all categorical variables, print out the area under curve (AUC) only it is greater or equal to 0.5. 
```{r}
for(v in catVars) {
  pi <- paste('pred', v, sep='')
  aucTrain <- calcAUC(dTrain[,pi], dTrain[,outcome]) 
  if (aucTrain >= 0.5) {
    aucCal <- calcAUC(dCal[,pi], dCal[,outcome]) 
    print(sprintf(
      "%s: trainAUC: %4.3f; calibrationAUC: %4.3f",
      pi, aucTrain, aucCal))
  }
}
```

#### Indicator
```{r}
indicator <- numericVars[grepl("isBAD", numericVars)]
numericVars <- setdiff(numericVars,indicator)
```

#### Numeric 
Function for SVM predictions for numeric variables.
```{r}
mkPredN <- function(outCol,varCol,appCol) {
  cuts <- unique(as.numeric(quantile(varCol, probs=seq(0, 1, 0.1), na.rm=T)))
  varC <- cut(varCol, cuts)
  appC <- cut(appCol, cuts)
  mkPredC(outCol, varC, appC)
}
```

Processing all numeric variables, print out the area under curve (AUC) only it is greater or equal to 0.5. 
```{r}
for(v in numericVars) {
  pi<-paste('pred',v,sep='')
  dTrain[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dTest[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dTest[,v])
  dCal[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dCal[,v])
  aucTrain <- calcAUC(dTrain[,pi],dTrain[,outcome])
  
  if(aucTrain>=0.5) {
    aucCal<-calcAUC(dCal[,pi],dCal[,outcome])
    print(sprintf(
      "%s, trainAUC: %4.3f calibrationAUC: %4.3f",
      pi,aucTrain,aucCal))
  }
}
```

#### Calculate loglikehood for feature selection
```{r}
# define function that calculate log likelihood
logLikelihood <- function(outCol, predCol, posl=pos) {
  sum(ifelse(outCol==pos, log(predCol), log(1-predCol)))
}
```

Log null
```{r}
baseRateCheck <- logLikelihood(dCal[,outcome], sum(dCal[,outcome]==pos)/length(dCal[,outcome]) )
```

Select categorical variables only if the log likelihood is over 500. 
```{r}
selPredVars <- c()
selVars <- c()
minStep <- 500

for(v in catVars) {
  pi <- paste('pred',v,sep='')
  liCheck <- 2*((logLikelihood(dCal[,outcome],dCal[,pi])
                 - baseRateCheck))
  if(liCheck>minStep) {
    print(sprintf("%s, calibrationScore: %g",pi,liCheck))
    selPredVars <- c(selPredVars,pi)
    selVars <- c(selVars, v)
  }
}
```

Select numeric variables only if the log likelihood is over 500. 
```{r}
for(v in numericVars) {
    pred <- paste(outcome, 'pred', v, sep='_')
    liCheck <- 2*((logLikelihood(dCal[,outcome], dCal[, pi]) - baseRateCheck) - 1)
    if(liCheck >= minStep) {
        print(sprintf("%s, calibrationScore: %g", v, liCheck))
        selPredVars <- c(selPredVars,pi)
        selVars     <- c(selVars, v)
    }
}
```

```{r}
selVars
```

### Multivariate models

```{r}
modelMeasure <- data.frame(modelname=character(), precision=double(), recall = double(), f1 = double(), trainAUC=double(), calAUC=double(), logLikelihood=double())
```

#### Model evaluation
Functions that plot graphs 
```{r}
# plot ROC curve
 plotROC <- function(pf,modelname="mn",titleString="ROC plot") { 
   ggplot() + 
     geom_line(data=pf, aes(x=FalsePositiveRate, y=TruePositiveRate), colour="red") +
     labs(title=paste(modelname, titleString)) +
     geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
     theme_bw()
 }

# distribution plot
distribution <- function(prediction, calTrue,modelname="mn"){
  ggplot(data.frame(predictions=prediction, calTrue = calTrue),
          aes(x=predictions, color=calTrue, linetype=calTrue)) +
          geom_density()  + 
          labs(title = paste(modelname, "Distribution Plot "), 
                             y = "Density", x = paste(modelname,"Prob")) +
          theme_bw()
}
```

Function that calculate performance.
```{r}
performanceMeasures <- function(pred, true, model.name = "model") {
  dev.norm <- -2 * logLikelihood(true, pred)/length(pred) 
  cmat <- table(actual = true, predicted = pred)
  accuracy <- sum(diag(cmat)) / sum(cmat)
  precision <- cmat[2, 2] / sum(cmat[, 2])
  recall <- cmat[2, 2] / sum(cmat[2, ])
  f1 <- 2 * precision * recall / (precision + recall) 
  data.frame(model = model.name, precision = precision,recall = recall, f1 = f1, dev.norm = dev.norm)
}
```


Function that print the graphs and table.
```{r}
performance <- function(model,dCal,cal_true,dTrain,train_true,predValue=TRUE,threshold=0.5,modelname){
  
  if (predValue){
    pred_value <- predict(model, newdata = dCal)[,pos]
    pred_train <- predict(model, newdata = dTrain)[,pos]
  }else {
    pred_value <- predict(model, newdata=dCal, type="response")
    pred_train <- predict(model, newdata=dTrain)
  }
  
  predObj <- ROCR::prediction(pred_value, cal_true)
  precObj <- ROCR::performance(predObj, "prec")
  recObj  <- ROCR::performance(predObj, "rec")
  perf    <- ROCR::performance(predObj, "tpr", "fpr")

  pf <- data.frame(FalsePositiveRate=perf@x.values[[1]],
                    TruePositiveRate=perf@y.values[[1]])
  
  print(plotROC(pf,modelname))
  
  print(distribution(pred_value, as.factor(cal_true),modelname))
  
  # precision <- (precObj@y.values)[[1]]
  # prec.x <- (precObj@x.values)[[1]]
  # recall <- (recObj@y.values)[[1]]
  # 
  # rocFrame <- data.frame(threshold=prec.x,
  #                          precision=precision,
  #                          recall=recall)
  
  pnull      <- mean(cal_true==pos)
  callog     <- logLikelihood(cal_true, pred_value)
  nulllog    <- logLikelihood(cal_true, pnull)
  trainAUC   <- calcAUC(pred_train, train_true)
  calAUC     <- calcAUC(pred_value, cal_true)

  trainperf_df <- performanceMeasures(train_true==pos, pred_train >= threshold, model.name="training")
  testperf_df <- performanceMeasures(cal_true==pos, pred_value >= threshold, model.name="calibration")
  print(testperf_df)
  perftable <- rbind(trainperf_df, testperf_df) 
  print(perftable)
  df <- data.frame(modelname,trainAUC,calAUC,callog)
  names(df) <- c("modelname","trainAUC", "calAUC", "logLikelihood")
  alldf <- cbind(df,testperf_df[,c(2,3,4)])
  modelMeasure <<- rbind(modelMeasure, alldf)
}
```

#### Decision Tree with all variables
```{r}
folmula <- paste(outcome,' ~ ', paste(c(c(setdiff(catVars,"OCCUPATION")),numericVars), collapse=' + '), sep='')
decision_tree_all <- rpart(folmula, data=dTrain)
```

```{r}
performance(decision_tree_all,dCal,dCal[,outcome],dTrain,dTrain[,outcome],predValue=TRUE, modelname="Decision Tree (all)")
```

#### Decision Tree with the selected variables

```{r}
folmula <- paste(outcome,' ~ ', paste((c(setdiff(selVars,"OCCUPATION"))), collapse=' + '), sep='')
decision_tree_sel <- rpart(folmula, data=dTrain)
```

```{r}
performance(decision_tree_sel,dCal,dCal[,outcome],dTrain,dTrain[,outcome],predValue=TRUE, modelname="Decision Tree (sel)")
```


















