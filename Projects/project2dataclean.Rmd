---
title: "CITS4009-Project 2"
output: prject2
---
#### Xiaoyu (21982644)

## Introduction
The dataset used for this project is pretty much the same as for the dataset used for project 1 (EDA) except this dataset has more observations. This dataset contains collected information on the mining injuries at U.S from 2000 to 2015 with 57 features and over 200,000 observations.

### Load Libraies
```{r}
library(dplyr)
library(vtreat)
library(ROCR)
library(ROCit)
library(rpart)
library(ggplot2)
library(knitr)
library(xgboost)
```

### Load the Data
```{r}
setwd("~/Downloads/CITS4009/Projects")
main <- read.csv("us_data.csv")
```

### Data Pre-processing
The data are cleaned as per project 1 with some modifications. Since we are already familiar with the data, this cleaning steps and explanation are not shown in full details. 

"DAYS_LOST","DAYS_RESTRICTED", "SCHEDULE_CHARGE" contain information about the degree of injury and, we'll get very good f1 score(0.988), recall(1), precision(0.977) for decision tree model. However, I don't thinks it's appropriate to include those variables in the model, it's more like telling the result rather than predict. 

Variable OCCUPATION will also be excluded from here, reasons for this is it contains too many levels (more than 180 categories) and even though the training set contains approximate 80% of the data, there were still some categories that in the calibration/test set but not in training set, which makes it hard to build the model. There are ways to solve this problem such as orders the levels of the OCCUPATION by the number of occurrence of each level in one class. However, in this project we'll exclude the variable.
```{r}
# select columns
keep <- c("SUBUNIT","ACCIDENT_DT","CAL_YR","CAL_QTR","ACCIDENT_TIME", "DEGREE_INJURY_CD", "FIPS_STATE_CD", "UG_LOCATION", "UG_MINING_METHOD", "MINING_EQUIP", "SHIFT_BEGIN_TIME", "CLASSIFICATION", "ACCIDENT_TYPE", "NO_INJURIES", "TOT_EXPER", "MINE_EXPER","JOB_EXPER", "ACTIVITY","INJURY_SOURCE","NATURE_INJURY", "INJ_BODY_PART", "TRANS_TERM", "RETURN_TO_WORK_DT", "IMMED_NOTIFY","COAL_METAL_IND")

injury <- main[which(names(main) %in% keep)]
```

```{r}
# change invalid value to NA and fill the NA
injury <- mutate(injury, ACCIDENT_TIME = ifelse(ACCIDENT_TIME > 2400, NA, ACCIDENT_TIME)) %>% mutate(injury,SHIFT_BEGIN_TIME= ifelse(SHIFT_BEGIN_TIME > 2400, NA, SHIFT_BEGIN_TIME))

# change the time in a range of 1-24
injury <- injury %>% mutate(ACCIDENT_TIME_NEW=case_when(
  ACCIDENT_TIME < 100  ~  floor(injury$ACCIDENT_TIME/10),
  ACCIDENT_TIME >= 100 ~ floor(injury$ACCIDENT_TIME/100))) %>% 
  mutate(SHIFT_BEGIN_TIME_NEW=case_when(
  SHIFT_BEGIN_TIME < 100  ~  floor(injury$SHIFT_BEGIN_TIME /10),
  SHIFT_BEGIN_TIME >= 100 ~ floor(injury$SHIFT_BEGIN_TIME /100)))

# fill the NA as the median based the ACCIDENT_TIME and SHIFT_BEGIN_TIME, from EDA process we know that those two values are higher related 

injury <- injury %>%
    group_by(SHIFT_BEGIN_TIME_NEW) %>%
    mutate(Amedian = median(ACCIDENT_TIME_NEW, na.rm=TRUE))  %>% group_by(ACCIDENT_TIME_NEW) %>%
    mutate(Smedian = median(SHIFT_BEGIN_TIME_NEW, na.rm=TRUE))

injury <- injury %>% mutate(SHIFT_BEGIN_TIME_NEW = ifelse(is.na(SHIFT_BEGIN_TIME_NEW),Smedian, SHIFT_BEGIN_TIME_NEW)) %>% mutate(ACCIDENT_TIME_NEW = ifelse(is.na(ACCIDENT_TIME_NEW),Amedian,ACCIDENT_TIME_NEW))
```

```{r}
# add a column as days return to work 
injury <- within(injury, {
     ACCIDENT_DT      <- as.POSIXct(ACCIDENT_DT, format='%d/%m/%Y')
     RETURN_TO_WORK_DT<- as.POSIXct(RETURN_TO_WORK_DT, format='%m/%d/%Y')
})

injury$DAY_AWY <- difftime(injury$RETURN_TO_WORK_DT,injury$ACCIDENT_DT, units="days")
injury$DAY_AWY <- as.numeric(injury$DAY_AWY)
```

```{r}
# fill NA for experience variables 
injury <- mutate(injury, TOT_EXPER_NEW = ifelse(is.na(TOT_EXPER),
                                                       JOB_EXPER,
                                                       TOT_EXPER))

injury <- mutate(injury, TOT_EXPER_NEW = ifelse(is.na(TOT_EXPER),
                                                       MINE_EXPER,
                                                       TOT_EXPER))

injury <- mutate(injury, JOB_EXPER_NEW = ifelse(is.na(JOB_EXPER),
                                                       TOT_EXPER,
                                                       JOB_EXPER))

injury <- mutate(injury, MINE_EXPER_NEW = ifelse(is.na(MINE_EXPER),
                                                       TOT_EXPER,
                                                       MINE_EXPER))
```

```{r}
# still have some NAs, use vtreat to prepare the data

 varlist <- setdiff(colnames(injury),"DEGREE_INJURY_CD")

 treatment_plan <- design_missingness_treatment(injury, varlist = varlist)

 training_prepared <- prepare(treatment_plan,injury)
```

```{r}
# remove injury df to free memory
rm(injury)
```

## Part 1 - Classification

### Select the target variable
The response variable chosen for this project is the degree of injury of the accident, no injured or injured.

I've focused on this target variable to help to classify whether the accidents will be if employee is injured it will cause days lost from work/days restricted etc. In this case, the company can plan ahead and take countermeasures.The labels assigned to this variable are no for not injured or yes for workers is injured because the accident. The aim of this project is to use a number of feature variables to create a classification model to assess if an incident will involve extra attention or if countermeasures are needed due to injury.

Create a target variable based on the the degree injury number. 0 and 6 indicate there that the employee had no injuries.
```{r}
training_prepared <-  training_prepared %>% 
                      subset(DEGREE_INJURY_CD %in% c("0", "1","2","3","4","5","6"))  %>%
                      mutate(DEGREE_INJURY_PRED = ifelse(DEGREE_INJURY_CD %in% c("0","6"), "no","yes"))%>%
                      mutate(DEGREE_INJURY_PRED = as.factor(DEGREE_INJURY_PRED))

table(training_prepared$DEGREE_INJURY_PRED)
```

The split between day lost and no day lost is not 1:1 balanced but are very close, so addition methods like under-sampling or over-sampling is not needed.
```{r}
round(prop.table(table(training_prepared$DEGREE_INJURY_PRED)), 2)
```

```{r message=FALSE, warning=FALSE}
for(d in names(training_prepared)) {
      if(setequal(deframe(unique(training_prepared[,d])),c(0,1))) training_prepared[, d] <- as.factor(training_prepared[, d])
}
```

### Select feature variables
Select input variables that are likely to be most useful to a model in order to predict the target variable, in this case, we want to select variables from the dataset that could help us to predict whether the incidents will cause day lost to the workers. The information gathered from EDA process and the data dictionary that was given are used to make an informed decision about the variable we could use. And this have almost done in the data cleaning step, which some variables were selected and kept in the previous step. However, we still need to filter some variables that created in previous step. 

```{r}
training_prepared <- training_prepared[,-which(names(training_prepared) %in% c("Amedian", "Smedian","ACCIDENT_DT","RETURN_TO_WORK_DT"))]
```

### Splitting
The code below is adapted from the lecture slide. 90% of the data will be used for training and the rest of them will be used for training. Out of the 90% of the training set, 10% of them will be used for calibration.
```{r}
set.seed(12345678)
rgroup <- runif(nrow(training_prepared)) < 0.9
dTrainAll <- training_prepared[rgroup,]
dTest <- training_prepared[!rgroup,]

outcomes <- c('DEGREE_INJURY_PRED','DEGREE_INJURY_CD')

vars <- setdiff(colnames(dTrainAll), outcomes)
catVars <- vars[sapply(dTrainAll[, vars], class) %in% c('factor', 'character')]
numericVars <- vars[sapply(dTrainAll[, vars], class) %in% c('numeric', 'integer')] 

useForCal <- rbinom(n=dim(dTrainAll)[1], size=1, prob=0.1) > 0 
dCal <- subset(dTrainAll, useForCal)
dTrain <- subset(dTrainAll, !useForCal)

rm(list=c('training_prepared','dTrainAll'))
```

### Single Variable Model(SVM)
#### Categorical
Function for SVM predictions for categorical variables.
```{r}
pos <- "yes"
mkPredC <- function(outCol, varCol, appCol) {
  pPos <- sum(outCol == pos) / length(outCol)
  naTab <- table(as.factor(outCol[is.na(varCol)]))
  pPosWna <- (naTab/sum(naTab))[pos]
  vTab <- table(as.factor(outCol), varCol)
  pPosWv <- (vTab[pos, ] + 1.0e-3*pPos) / (colSums(vTab) + 1.0e-3) 
  pred <- pPosWv[appCol]
  pred[is.na(appCol)] <- pPosWna
  pred[is.na(pred)] <- pPos
  pred
}
```

Data type has change to multi-type, need to change back to data.frame only.
```{r}
dTrain <- as.data.frame(dTrain)
dCal <- as.data.frame(dCal)
dTest <- as.data.frame(dTest)
```

```{r}
outcome <- "DEGREE_INJURY_PRED"
for(v in catVars) {
  pi <- paste('pred',v,sep='')
  dTrain[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dCal[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dCal[,v])
  dTest[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTest[,v])
}
```

Evaluate SVM for categorical variables.
```{r}
calcAUC <- function(predcol,outcol) {
  perf <- ROCR::performance(prediction(predcol,outcol==pos),'auc')
  as.numeric(perf@y.values) 
}
```

Processing all categorical variables, print out the area under curve (AUC) only it is greater or equal to 0.5. 
```{r}
for(v in catVars) {
  pi <- paste('pred', v, sep='')
  aucTrain <- calcAUC(dTrain[,pi], dTrain[,outcome]) 
  if (aucTrain >= 0.5) {
    aucCal <- calcAUC(dCal[,pi], dCal[,outcome]) 
    print(sprintf(
      "%s: trainAUC: %4.3f; calibrationAUC: %4.3f",
      pi, aucTrain, aucCal))
  }
}
```

#### Indicator
```{r}
indicator <- numericVars[grepl("isBAD", numericVars)]
numericVars <- setdiff(numericVars,indicator)
```

#### Numeric 
Function for SVM predictions for numeric variables.
```{r}
mkPredN <- function(outCol,varCol,appCol) {
  cuts <- unique(as.numeric(quantile(varCol, probs=seq(0, 1, 0.1), na.rm=T)))
  varC <- cut(varCol, cuts)
  appC <- cut(appCol, cuts)
  mkPredC(outCol, varC, appC)
}
```

Processing all numeric variables, print out the area under curve (AUC) only it is greater or equal to 0.5. 
```{r}
for(v in numericVars) {
  pi<-paste('pred',v,sep='')
  dTrain[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dTest[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dTest[,v])
  dCal[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dCal[,v])
  aucTrain <- calcAUC(dTrain[,pi],dTrain[,outcome])
  
  if(aucTrain>=0.5) {
    aucCal<-calcAUC(dCal[,pi],dCal[,outcome])
    print(sprintf(
      "%s, trainAUC: %4.3f calibrationAUC: %4.3f",
      pi,aucTrain,aucCal))
  }
}
```

#### Calculate loglikelihood for feature selection
```{r}
# define function that calculate log likelihood
logLikelihood <- function(outCol, predCol, posl=pos) {
  sum(ifelse(outCol==pos, log(predCol), log(1-predCol)))
}
```

Log null
```{r}
baseRateCheck <- logLikelihood(dCal[,outcome], sum(dCal[,outcome]==pos)/length(dCal[,outcome]) )
```

Select categorical variables only if the log likelihood is over 500. 
```{r}
selPredVars <- c()
selVars <- c()
minStep <- 500

for(v in catVars) {
  pi <- paste('pred',v,sep='')
  liCheck <- 2*((logLikelihood(dCal[,outcome],dCal[,pi])
                 - baseRateCheck))
  if(liCheck>minStep) {
    print(sprintf("%s, calibrationScore: %g",pi,liCheck))
    selPredVars <- c(selPredVars,pi)
    selVars <- c(selVars, v)
  }
}
```

Select numeric variables only if the log likelihood is over 500. 
```{r}
for(v in numericVars) {
    pred <- paste(outcome, 'pred', v, sep='_')
    liCheck <- 2*((logLikelihood(dCal[,outcome], dCal[, pi]) - baseRateCheck) - 1)
    if(liCheck >= minStep) {
        print(sprintf("%s, calibrationScore: %g", v, liCheck))
        selPredVars <- c(selPredVars,pi)
        selVars     <- c(selVars, v)
    }
}
```

```{r}
selVars
```

### Multivariate models

Data frame that store the model and performance measure for models.
```{r}
modelMeasure <- data.frame(modelname=character(), precision=double(), recall = double(), f1 = double(), accuracy = double(), trainAUC=double(), calAUC=double(), logLikelihood=double())
```

#### Model evaluation
Functions that plot graphs 
```{r}
# plot ROC curve
 plotROC <- function(pf,modelname="mn",titleString="ROC plot") { 
   ggplot() + 
     geom_line(data=pf, aes(x=FalsePositiveRate, y=TruePositiveRate), colour="red") +
     labs(title=paste(modelname, titleString)) +
     geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
     theme_bw()
 }

# distribution plot
distribution <- function(prediction, calTrue,modelname="mn"){
  ggplot(data.frame(predictions=prediction, calTrue = calTrue),
          aes(x=predictions, color=calTrue, linetype=calTrue)) +
          geom_density()  + 
          labs(title = paste(modelname, "Distribution Plot "), 
                             y = "Density", x = paste(modelname,"Prob")) +
          theme_bw()
}
```

Function that calculate performance.
```{r}
performanceMeasures <- function(pred, true, model.name = "model",threshold) {
  dev.norm <- -2 * logLikelihood(true, pred)/length(pred) 
  cmat <- table(actual = true, predicted = (pred > threshold))
  accuracy <- sum(diag(cmat)) / sum(cmat)
  precision <- cmat[2, 2] / sum(cmat[, 2])
  recall <- cmat[2, 2] / sum(cmat[2, ])
  f1 <- 2 * precision * recall / (precision + recall)
  list(cmat,data.frame(model = model.name, precision = precision,recall = recall, f1 = f1, accuracy = accuracy))
}
```

Function that print the graphs and table.
```{r}
performance <- function(model,dCal,cal_true,dTrain,train_true,predValue=TRUE,threshold=0.5,modelname){
  
  if (predValue){
    pred_value <- predict(model, newdata = dCal)[,pos]
    pred_train <- predict(model, newdata = dTrain)[,pos]
  }else {
    pred_value <- predict(model, newdata=dCal, type="response")
    pred_train <- predict(model, newdata=dTrain)
  }
  
  predObj <- ROCR::prediction(pred_value, cal_true)
  precObj <- ROCR::performance(predObj, "prec")
  recObj  <- ROCR::performance(predObj, "rec")
  perf    <- ROCR::performance(predObj, "tpr", "fpr")

  pf <- data.frame(FalsePositiveRate=perf@x.values[[1]],
                    TruePositiveRate=perf@y.values[[1]])
  
  print(plotROC(pf,modelname))
  
  print(distribution(pred_value, as.factor(cal_true),modelname))
  
  # precision <- (precObj@y.values)[[1]]
  # prec.x <- (precObj@x.values)[[1]]
  # recall <- (recObj@y.values)[[1]]
  # 
  # rocFrame <- data.frame(threshold=prec.x,
  #                          precision=precision,
  #                          recall=recall)
  
  pnull      <- mean(cal_true==pos)
  callog     <- logLikelihood(cal_true, pred_value)
  nulllog    <- logLikelihood(cal_true, pnull)
  trainAUC   <- calcAUC(pred_train, train_true)
  calAUC     <- calcAUC(pred_value, cal_true)

  trainperf_df <- performanceMeasures(train_true==pos, pred_train >= threshold, model.name="training",threshold)
  testperf_df <- performanceMeasures(cal_true==pos, pred_value >= threshold, model.name="calibration",threshold)
  train_df   <- trainperf_df[[2]]
  test_df <- testperf_df[[2]]
  perftable   <- rbind(train_df,test_df) 
  print(kable(testperf_df[[1]]))
  print(perftable)
  df <- data.frame(modelname,trainAUC,calAUC,callog)
  names(df) <- c("modelname","trainAUC", "calAUC", "logLikelihood")
  alldf <- cbind(df,test_df[,c(2,3,4,5)])
  modelMeasure <<- rbind(modelMeasure, alldf)
}
```

#### Decision Tree with all variables
```{r}
formula <- paste(outcome,' ~ ', paste(c(catVars,numericVars), collapse=' + ', sep=''))
decision_tree_all <- rpart(formula, data=dTrain)
```

```{r}
performance(decision_tree_all,dCal,dCal[,outcome],dTrain,dTrain[,outcome],predValue=TRUE, modelname="Decision Tree (all)")
```

#### Decision Tree with the selected variables

```{r}
formula <- paste(outcome,' ~ ', paste(selVars, collapse=' + '), sep='')
decision_tree_sel <- rpart(formula, data=dTrain)
```

```{r}
performance(decision_tree_sel,dCal,dCal[,outcome],dTrain,dTrain[,outcome],predValue=TRUE, modelname="Decision Tree (sel)")
```

#### Logistic Regression with all variables
```{r message=FALSE, warning=FALSE}
dTrain$DEGREE_INJURY_PRED <- as.factor(dTrain$DEGREE_INJURY_PRED)
formula <- paste(outcome, paste(c(catVars,numericVars), collapse=" + "), sep=" ~ ")
logr_all <- glm(formula=formula, data=dTrain, family=binomial(link="logit"))
```

```{r message=FALSE, warning=FALSE}
performance(logr_all,dCal,dCal[,outcome],dTrain,dTrain[,outcome],predValue=FALSE, modelname="LogisticR (all)")
```

```{r message=FALSE, warning=FALSE}
formula <- paste(outcome, paste(selVars, collapse=" + "), sep=" ~ ")
logr_sel <- glm(formula=formula, data=dTrain, family=binomial(link="logit"))
```

```{r message=FALSE, warning=FALSE}
performance(logr_sel,dCal,dCal[,outcome],dTrain,dTrain[,outcome],predValue=FALSE, modelname="LogisticR (sel)")
```

#### XGBoost

```{r}
tplan <- vtreat::designTreatmentsZ(dTrain, varlist, 
                                   minFraction= 0.025,
                                   verbose=FALSE)
sf <- tplan$scoreFrame
newvars <- sf$varName[sf$code %in% c("lev", "clean", "isBAD")]

trainVtreat <- as.matrix(vtreat::prepare(tplan, dTrain, varRestriction = newvars))
calVtreat <- as.matrix(vtreat::prepare(tplan, dCal, varRestriction = newvars))
testVtreat <- as.matrix(vtreat::prepare(tplan, dTest, varRestriction = newvars))
```

```{r}
cv <- xgb.cv(trainVtreat, 
             label = dTrain[,outcome]==pos,
             params=list(objective="binary:logistic"),
             nfold=5,
             nrounds=100,
             print_every_n=10,
             metrics="logloss")

evalframe <- as.data.frame(cv$evaluation_log)
NROUNDS <- which.min(evalframe$test_logloss_mean)
```

```{r}
xgboost_model <- xgboost(data=trainVtreat, 
                 label=dTrain[,outcome]==pos,
                 params=list(objective="binary:logistic"),
                 nrounds=NROUNDS,
                 verbose=FALSE)
```


```{r}
performance(xgboost_model,calVtreat,dCal[,outcome],trainVtreat,dTrain[,outcome],predValue=FALSE, modelname="xgboost")
```
















